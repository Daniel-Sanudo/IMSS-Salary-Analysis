{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "040a9cfd",
   "metadata": {},
   "source": [
    "# Dataset sourcing\n",
    "\n",
    "## API method\n",
    "\n",
    "Salary information from years 1997 to 2018 can be accessed using the IMSS api endpoint with the following structure:\n",
    "\n",
    "```\n",
    "http://datos.imss.gob.mx/api/action/datastore/search.json?resource_id={resource_id}\n",
    "```\n",
    "\n",
    "Where __resource_id__ is the identifier for the files stored for each year. \n",
    "\n",
    "The API method get is not reliable since some of the endpoints return blank jsons or have not been uploaded.\n",
    "\n",
    "## Web scraping method\n",
    "\n",
    "Salary information from years 2019 to the current year (2022) is not yet available in the API endpoint, therefore it will have to be downloaded using a webscraper that can access the following url:\n",
    "\n",
    "```\n",
    "http://datos.imss.gob.mx/dataset/asg-{year}\n",
    "```\n",
    "\n",
    "Where __year__ corresponds to the target year.\n",
    "\n",
    "After accesing the target url, the next step is to gather all the relative urls for each of the 12 files per year.\n",
    "\n",
    "The HTML element for each of the target files follows this structure\n",
    "\n",
    "```\n",
    "<a href=\"/dataset/asg{year}/resource/asg-{year}-{month}-{day}\" class=\"heading\" title=\"asg-{year}-{month}-{day}\" property=\"dcat:accessURL\">asg-{year}-{month}-{day}<span class=\"format-label\" property=\"dc:format\" data-format=\"csv\">csv</span></a>\n",
    "```\n",
    "\n",
    "Where __year__ corresponds to the target year, __month__ is the target month for the specified year, __day__ is the last day for the target month and year.\n",
    "\n",
    "After joining the base url with the relative url extracted from the html elements, the result would be the following:\n",
    "\n",
    "```\n",
    "http://datos.imss.gob.mx/dataset/asg2020/resource/asg-{year}-{month}-{day}\n",
    "```\n",
    "\n",
    "Inside this url, the next step is to locate the following html element:\n",
    "\n",
    "```\n",
    "<a href=\"/node/{id}/download\" class=\"btn-primary btn\"><i class=\"icon-large icon-download\"></i> Descargar</a>\n",
    "```\n",
    "\n",
    "Where __id__ is the number of the csv file, usually in a 4 digit format. Joining this url with the base url gives the final path to download the required csv.\n",
    "\n",
    "Each of these csv files is around 400 megabytes. Assuming all files for the 26 years have the same filesize, it would be a total size of 120 gigabytes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec064748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter, BeautifulSoup, and Pandas\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from selenium import webdriver\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcf9a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_year(target_year,target_month='All'):\n",
    "    # Create options chrome options instance\n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    # Create options dictionary\n",
    "    prefs = {\"download.default_directory\" : \"/IMSS_Files/\",\n",
    "            \"download.directory_upgrade\": \"true\",\n",
    "            \"download.prompt_for_download\": \"false\",\n",
    "            \"disable-popup-blocking\": \"false\"}\n",
    "    \n",
    "    # Add options dictionary to options instance\n",
    "    options.add_experimental_option(\"prefs\", prefs)\n",
    "    \n",
    "    # Install chrome driver manager\n",
    "    executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "    \n",
    "    # Initiate automated browser with preferred options, setting headless to False for debugging\n",
    "    browser = Browser('chrome', **executable_path, headless=False, options=options)\n",
    "    \n",
    "    scrape_month(browser,target_year,target_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d29bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_month(browser,year,month):\n",
    "    \n",
    "    # Set the target url according to the year argument\n",
    "    target_url = f'http://datos.imss.gob.mx/dataset/asg-{year}'\n",
    "    \n",
    "    # Acess the url for the target year\n",
    "    browser.visit(target_url)\n",
    "    \n",
    "    if month == 'All':\n",
    "        \n",
    "        # Create list to store the list of extracted urls as strings\n",
    "        links_for_each_month = []\n",
    "        \n",
    "        # Loop through the urls that match the search text asg-{year}\n",
    "        for link in browser.links.find_by_partial_text(f'asg-{year}'):\n",
    "            \n",
    "            # Append the link as a string to avoid stale element error\n",
    "            links_for_each_month.append(str(link['href']))\n",
    "        \n",
    "        # Loop through the link list given by links_for_each_month\n",
    "        for link in links_for_each_month:\n",
    "            \n",
    "            # Visit the new url\n",
    "            browser.visit(link)\n",
    "            \n",
    "            # Look for the url that includes node to find the csv\n",
    "            for link in browser.links.find_by_partial_href('node'):\n",
    "                \n",
    "                # Store the link as a string to avoid stale element error\n",
    "                csv_link = str(link['href'])\n",
    "            \n",
    "            # Debug to get the link which will be downloaded\n",
    "            print(csv_link)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0df08f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://datos.imss.gob.mx/node/1113/api\n",
      "http://datos.imss.gob.mx/node/1116/api\n",
      "http://datos.imss.gob.mx/node/1118/api\n",
      "http://datos.imss.gob.mx/node/1120/api\n",
      "http://datos.imss.gob.mx/node/1125/api\n",
      "http://datos.imss.gob.mx/node/1129/api\n",
      "http://datos.imss.gob.mx/node/1131/api\n",
      "http://datos.imss.gob.mx/node/1133/api\n",
      "http://datos.imss.gob.mx/node/1135/api\n",
      "http://datos.imss.gob.mx/node/1137/api\n",
      "http://datos.imss.gob.mx/node/1142/api\n",
      "http://datos.imss.gob.mx/node/1146/api\n"
     ]
    }
   ],
   "source": [
    "scrape_year(2021)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
